---
title: "HW03"
author: "Eleanor King, elejking"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(288942)
library(tidyverse)
```

## Question 1 (10 pts)

Consider the distribution given by the density:

$$f(x) = \frac{1}{\theta}, x \in [0, \theta], \theta > 0$$

We saw on the previous homework that we could estimate $\theta$ using:

-   Method of Moments: $\tilde \theta = 2 \bar X$
-   Maximum Likelihood $\hat \theta = \max_{i} X_i$

In this homework, we will explore the duality between estimators and test statistics.

### Part (a) (2 pts)

Suppose we wish to test the hypothesis that $\theta = 50$ against the alternative that $\theta = 51$. We will suppose we have a sample size of $n = 56$ observations.

$$H_0: \theta = 50 \text{ vs } H_1: \theta = 51$$

As test statistics, we can use the estimators given above.

Suppose the true $\theta = 50$. Find the null distribution for $\tilde \theta$ (method of moments) under when $\theta = 50$ and the alternative distribution when $\theta = 51$. Use 10,000 Monte Carlo replications (i.e., 10,000 samples of 56 observations) .

Find a rejection region of the form $\tilde \theta > c$ such that $P(\tilde \theta > c \mid H_0) \le 0.05$. Find the power of this region when $\theta = 51$.

Here's some code to get you started:

```{r, cache = TRUE}
null_samples <- data.frame(replicate(10000, { runif(56, min = 0, max = 50)}))
alt_samples  <- data.frame(replicate(10000, { runif(56, min = 0, max = 51)}))
# you can use map_dbl() to compute your test statistic on each sample.
#theta_null <- 50
#theta_alt <- 51

t_stat_null <- map_dbl(null_samples, ~ 2 * mean(.x))
t_stat_alt <- map_dbl(alt_samples, ~ 2 * mean(.x))

rej_region <- quantile(t_stat_null, 0.95)
power <- mean(t_stat_alt > rej_region)
# reject the null if t_stat_null is > rej_region
rej_region
power

```

### Part (b) (2 pts)

Repeat this process using $\hat \theta$ (the MLE statistic).
```{r, cache = TRUE}
null_samples <- data.frame(replicate(10000, { runif(56, min = 0, max = 50)}))
alt_samples  <- data.frame(replicate(10000, { runif(56, min = 0, max = 51)}))
# you can use map_dbl() to compute your test statistic on each sample.
t_stat_null <- map_dbl(null_samples, max)
t_stat_alt <- map_dbl(alt_samples, max)

rej_region_mle <- quantile(t_stat_null, 0.95)
power_mle <- mean(t_stat_alt > rej_region_mle)
# reject the null if t_stat_null is > rej_region_mle
rej_region_mle
power_mle
```
### Part (c) (2 pts)

Create a power curve for each method evaluated at the following alternative distributions. Save some time, feel free to only use 1000 samples (of 56 observations each) per alternative hypothesis.

```{r}
## Sample code from Dr. Fredrickson

#k <- 10000 # replications
#n <- 25 # sample size

#mean_0 <- replicate(k, {
#  rexp(n, rate = 1) |> mean()
#})

#median_0 <- replicate(k, {
#  rexp(n, rate = 1) |> median()
#})

#mean_1 <- replicate(k, {
#  rexp(n, rate = 2) |> mean()
#})

#median_1 <- replicate(k, {
#  rexp(n, rate = 2) |> median()
#})

#mm0 <-
#  bind_rows(
#    data.frame(t = mean_0, stat = "mean", hypothesis = "Null"),
#    data.frame(t = mean_1, stat = "mean", hypothesis = "Alt"),
#    data.frame(t = median_0, stat = "median", hypothesis = "Null"),
#    data.frame(t = median_1, stat = "median", hypothesis = "Alt"))

#ggplot(mm0, aes(x = t, fill = hypothesis)) + geom_density(alpha = 0.5) + facet_wrap(~ stat)
```

How large does $\theta$ have to be to achieve $>80$% power for each of the methods?
```{r}

```

### Part (d) (2 pts)

Explain your findings in (a) - (c) to an audience that has a background in statistics but is not familiar with using Monte Carlo integration to estimate operating characteristics. What would you tell this audience about these two test statistics.

```{r}
# Monte Carlo integration allows us to introduce simualted random samples to approximate integrals efficiently and determine the power of test statistics like mean, median, and MLE. In particular, we found a rejection region based on random samples from the null distribution and calculated power by finding how often samples fall in the rejection region. In this case, the mean, MLE, and median statistics were not very useful at estimation since the difference in the hypotheses was relatively small. Power is relatively low given the proximity of the hypotheses. 
```

### Part (e) (2 pts)

```{r echo = FALSE}
fish <- structure(list(Obs = 1:159, Species = c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L), Weight = c(242, 290, 340, 
363, 430, 450, 500, 390, 450, 500, 475, 500, 500, NA, 600, 600, 
700, 700, 610, 650, 575, 685, 620, 680, 700, 725, 720, 714, 850, 
1000, 920, 955, 925, 975, 950, 270, 270, 306, 540, 800, 1000, 
40, 69, 78, 87, 120, 0, 110, 120, 150, 145, 160, 140, 160, 169, 
161, 200, 180, 290, 272, 390, 55, 60, 90, 120, 150, 140, 170, 
145, 200, 273, 300, 6.7, 7.5, 7, 9.7, 9.8, 8.7, 10, 9.9, 9.8, 
12.2, 13.4, 12.2, 19.7, 19.9, 200, 300, 300, 300, 430, 345, 456, 
510, 540, 500, 567, 770, 950, 1250, 1600, 1550, 1650, 5.9, 32, 
40, 51.5, 70, 100, 78, 80, 85, 85, 110, 115, 125, 130, 120, 120, 
130, 135, 110, 130, 150, 145, 150, 170, 225, 145, 188, 180, 197, 
218, 300, 260, 265, 250, 250, 300, 320, 514, 556, 840, 685, 700, 
700, 690, 900, 650, 820, 850, 900, 1015, 820, 1100, 1000, 1100, 
1000, 1000), Length1 = c(23.2, 24, 23.9, 26.3, 26.5, 26.8, 26.8, 
27.6, 27.6, 28.5, 28.4, 28.7, 29.1, 29.5, 29.4, 29.4, 30.4, 30.4, 
30.9, 31, 31.3, 31.4, 31.5, 31.8, 31.9, 31.8, 32, 32.7, 32.8, 
33.5, 35, 35, 36.2, 37.4, 38, 23.6, 24.1, 25.6, 28.5, 33.7, 37.3, 
12.9, 16.5, 17.5, 18.2, 18.6, 19, 19.1, 19.4, 20.4, 20.5, 20.5, 
21, 21.1, 22, 22, 22.1, 23.6, 24, 25, 29.5, 13.5, 14.3, 16.3, 
17.5, 18.4, 19, 19, 19.8, 21.2, 23, 24, 9.3, 10, 10.1, 10.4, 
10.7, 10.8, 11.3, 11.3, 11.4, 11.5, 11.7, 12.1, 13.2, 13.8, 30, 
31.7, 32.7, 34.8, 35.5, 36, 40, 40, 40.1, 42, 43.2, 44.8, 48.3, 
52, 56, 56, 59, 7.5, 12.5, 13.8, 15, 15.7, 16.2, 16.8, 17.2, 
17.8, 18.2, 19, 19, 19, 19.3, 20, 20, 20, 20, 20, 20.5, 20.5, 
20.7, 21, 21.5, 22, 22, 22.6, 23, 23.5, 25, 25.2, 25.4, 25.4, 
25.4, 25.9, 26.9, 27.8, 30.5, 32, 32.5, 34, 34, 34.5, 34.6, 36.5, 
36.5, 36.6, 36.9, 37, 37, 37.1, 39, 39.8, 40.1, 40.2, 41.1), 
    Lenght2 = c(25.4, 26.3, 26.5, 29, 29, 29.7, 29.7, 30, 30, 
    30.7, 31, 31, 31.5, 32, 32, 32, 33, 33, 33.5, 33.5, 34, 34, 
    34.5, 35, 35, 35, 35, 36, 36, 37, 38.5, 38.5, 39.5, 41, 41, 
    26, 26.5, 28, 31, 36.4, 40, 14.1, 18.2, 18.8, 19.8, 20, 20.5, 
    20.8, 21, 22, 22, 22.5, 22.5, 22.5, 24, 23.4, 23.5, 25.2, 
    26, 27, 31.7, 14.7, 15.5, 17.7, 19, 20, 20.7, 20.7, 21.5, 
    23, 25, 26, 9.8, 10.5, 10.6, 11, 11.2, 11.3, 11.8, 11.8, 
    12, 12.2, 12.4, 13, 14.3, 15, 32.3, 34, 35, 37.3, 38, 38.5, 
    42.5, 42.5, 43, 45, 46, 48, 51.7, 56, 60, 60, 63.4, 8.4, 
    13.7, 15, 16.2, 17.4, 18, 18.7, 19, 19.6, 20, 21, 21, 21, 
    21.3, 22, 22, 22, 22, 22, 22.5, 22.5, 22.7, 23, 23.5, 24, 
    24, 24.6, 25, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28, 28.7, 
    30, 32.8, 34.5, 35, 36.5, 36, 37, 37, 39, 39, 39, 40, 40, 
    40, 40, 42, 43, 43, 43.5, 44), Lenght3 = c(30, 31.2, 31.1, 
    33.5, 34, 34.7, 34.5, 35, 35.1, 36.2, 36.2, 36.2, 36.4, 37.3, 
    37.2, 37.2, 38.3, 38.5, 38.6, 38.7, 39.5, 39.2, 39.7, 40.6, 
    40.5, 40.9, 40.6, 41.5, 41.6, 42.6, 44.1, 44, 45.3, 45.9, 
    46.5, 28.7, 29.3, 30.8, 34, 39.6, 43.5, 16.2, 20.3, 21.2, 
    22.2, 22.2, 22.8, 23.1, 23.7, 24.7, 24.3, 25.3, 25, 25, 27.2, 
    26.7, 26.8, 27.9, 29.2, 30.6, 35, 16.5, 17.4, 19.8, 21.3, 
    22.4, 23.2, 23.2, 24.1, 25.8, 28, 29, 10.8, 11.6, 11.6, 12, 
    12.4, 12.6, 13.1, 13.1, 13.2, 13.4, 13.5, 13.8, 15.2, 16.2, 
    34.8, 37.8, 38.8, 39.8, 40.5, 41, 45.5, 45.5, 45.8, 48, 48.7, 
    51.2, 55.1, 59.7, 64, 64, 68, 8.8, 14.7, 16, 17.2, 18.5, 
    19.2, 19.4, 20.2, 20.8, 21, 22.5, 22.5, 22.5, 22.8, 23.5, 
    23.5, 23.5, 23.5, 23.5, 24, 24, 24.2, 24.5, 25, 25.5, 25.5, 
    26.2, 26.5, 27, 28, 28.7, 28.9, 28.9, 28.9, 29.4, 30.1, 31.6, 
    34, 36.5, 37.3, 39, 38.3, 39.4, 39.3, 41.4, 41.4, 41.3, 42.3, 
    42.5, 42.4, 42.5, 44.6, 45.2, 45.5, 46, 46.6), Heightpct = c(38.4, 
    40, 39.8, 38, 36.6, 39.2, 41.1, 36.2, 39.9, 39.3, 39.4, 39.7, 
    37.8, 37.3, 40.2, 41.5, 38.8, 38.8, 40.5, 37.4, 38.3, 40.8, 
    39.1, 38.1, 40.1, 40, 40.3, 39.8, 40.6, 44.5, 40.9, 41.1, 
    41.4, 40.6, 37.9, 29.2, 27.8, 28.5, 31.6, 29.7, 28.4, 25.6, 
    26.1, 26.3, 25.3, 28, 28.4, 26.7, 25.8, 23.5, 27.3, 27.8, 
    26.2, 25.6, 27.7, 25.9, 27.6, 25.4, 30.4, 28, 27.1, 41.5, 
    37.8, 37.4, 39.4, 39.7, 36.8, 40.5, 40.4, 40.1, 39.6, 39.2, 
    16.1, 17, 14.9, 18.3, 16.8, 15.7, 16.9, 16.9, 16.7, 15.6, 
    18, 16.5, 18.9, 18.1, 16, 15.1, 15.3, 15.8, 18, 15.6, 16, 
    15, 17, 14.5, 16, 15, 16.2, 17.9, 15, 15, 15.9, 24, 24, 23.9, 
    26.7, 24.8, 27.2, 26.8, 27.9, 24.7, 24.2, 25.3, 26.3, 25.3, 
    28, 26, 24, 26, 25, 23.5, 24.4, 28.3, 24.6, 21.3, 25.1, 28.6, 
    25, 25.7, 24.3, 24.3, 25.6, 29, 24.8, 24.4, 25.2, 26.6, 25.2, 
    24.1, 29.5, 28.1, 30.8, 27.9, 27.7, 27.5, 26.9, 26.9, 26.9, 
    30.1, 28.2, 27.6, 29.2, 26.2, 28.7, 26.4, 27.5, 27.4, 26.8
    ), ` Widthpct` = c(13.4, 13.8, 15.1, 13.3, 15.1, 14.2, 15.3, 
    13.4, 13.8, 13.7, 14.1, 13.3, 12, 13.6, 13.9, 15, 13.8, 13.5, 
    13.3, 14.8, 14.1, 13.7, 13.3, 15.1, 13.8, 14.8, 15, 14.1, 
    14.9, 15.5, 14.3, 14.3, 14.9, 14.7, 13.7, 14.8, 14.5, 15.2, 
    19.3, 16.6, 15, 14, 13.9, 13.7, 14.3, 16.1, 14.7, 14.7, 13.9, 
    15.2, 14.6, 15.1, 13.3, 15.2, 14.1, 13.6, 15.4, 14, 15.4, 
    15.6, 15.3, 14.1, 13.3, 13.5, 13.7, 14.7, 14.2, 14.7, 13.1, 
    14.2, 14.8, 14.6, 9.7, 10, 9.9, 11.5, 10.3, 10.2, 9.8, 8.9, 
    8.7, 10.4, 9.4, 9.1, 13.6, 11.6, 9.7, 11, 11.3, 10.1, 11.3, 
    9.7, 9.5, 9.8, 11.2, 10.2, 10, 10.5, 11.2, 11.7, 9.6, 9.6, 
    11, 16, 13.6, 15.2, 15.3, 15.9, 17.3, 16.1, 15.1, 14.6, 13.2, 
    15.8, 14.7, 16.3, 15.5, 14.5, 15, 15, 15, 17, 15.1, 15.1, 
    15, 14.8, 14.9, 14.6, 15, 15.9, 13.9, 15.7, 14.8, 17.9, 15, 
    15, 15.8, 14.3, 15.4, 15.1, 17.7, 17.5, 20.9, 17.6, 17.6, 
    15.9, 16.2, 18.1, 14.5, 17.8, 16.8, 17, 17.6, 15.6, 15.4, 
    16.1, 16.3, 17.7, 16.3), Sex = c(NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, 1L, 1L, NA, 1L, NA, NA, NA, 1L, 
    NA, NA, NA, NA, 1L, NA, NA, NA, 0L, 0L, NA, 1L, 0L, NA, NA, 
    NA, NA, NA, 0L, NA, NA, NA, NA, NA, NA, NA, 0L, 0L, 0L, 0L, 
    0L, NA, 0L, NA, NA, 0L, NA, NA, 0L, NA, NA, 1L, 1L, 1L, NA, 
    NA, 0L, 0L, NA, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, NA, 0L, NA, NA, NA, 1L, NA, NA, NA, NA, 
    0L, 0L, NA, NA, NA, 0L, 0L, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, 1L, 0L, 0L, NA, NA, NA, 0L, 0L, 0L, NA, NA, 
    NA, NA, NA, NA, 0L, NA, NA, 0L, 0L, NA, 0L, NA, 0L, 0L, NA, 
    NA, 0L, 0L, 0L, 0L, 0L, 0L, NA, NA, 0L, 0L, 0L, 0L, 0L, 0L, 
    0L, 1L, 0L)), class = "data.frame", row.names = c(NA, -159L
)) 
```

This file includes a sample of fish caught by the University of Helsinki, including their lengths. Using the `length1` measurement and a test statistic of your choice, test the hypothesis that Perch (species code 7) are uniformly distributed between 0 and 50cm against the alternative that they are uniform between 0 and 51cm.

```{r}
#H_0 = lengths of perch are uniformly distributed between 0 and 50 cm
#H_1 = lengths of perch are uniformly distibured between 0 and 51cm

perch <- fish %>% filter(Species == 7)
perch_length <- perch$Length1

theta_0 <- 50
theta_1 <- 51
theta_hat <- max(perch_length)

null_samples <- replicate(10000, max(runif(length(perch_length), 0, theta_0)))
crit_val <- quantile(null_samples, 0.95)

theta_hat
crit_val
## theta_hat < crit_val, therefore we fail to reject the null hypothesis that lengths are uniformly distributed between 0 and 50 cm.
```

## Problem 2 (10 pts)

In the previous problem, we tested a hypothesis that stated that the distribution of the length of Perch was uniform within the interval $[0, \theta]$. Plotting out the fish data, we see this assumption may not seem plausible:

```{r}
ggplot(filter(fish, Species == 7), aes(x = Length1)) + geom_histogram(fill = "blue", bins = 10)
```

A slightly more flexible model is given by a **truncated Normal distribution**:

$$f(x) = I(x \in [0, \theta]) \, c(\mu, \sigma^2, \theta) \, \frac{1}{\sqrt{2\pi \sigma^2}}\exp\left\{ -\frac{(x - \mu)^2}{2\sigma^2} \right\}$$ where $I(x \in [0, \theta])$ is the indicator function for the event that $x$ is in the region $[0, \theta]$ and $c$ is a function of the parameters that ensures that $f$ is a valid density function (i.e., it integrates to 1 over the region $[0, \theta]$).

We'll fix $\theta = 50$. Here are some example truncated normal distributions:

```{r}
f <- function(x, mu, s2) { 
  const <- 1/(pnorm(50, mean = mu, sd = sqrt(s2)) -
                pnorm(0, mean = mu, sd = sqrt(s2)))
  ifelse(0 <= x & x <= 50,
         const * dnorm(x, mean = mu, sd = sqrt(s2)),
         0
  )  
}
curve(f(x, mu = 25, s2 = 60), from = -1, to  = 60)
curve(f(x, mu = 40, s2 = 100), add = TRUE, lty = 2)
curve(f(x, mu = 20, s2 = 1000), add = TRUE, lty = 3)
legend(x = "topright", legend = c("25, 60", "40, 100", "20, 1000"), lty = 1:3)
```

### Part (a) (2 pts)

Let $Z \sim N(\mu, \sigma^2)$. Let $X$ be a truncated Normal with the same $\mu$ and $\sigma^2$, but truncated on the interval $[0, \theta]$.

**Prove** that the CDF $F(x) = P(X \le x)$ is equal to: $$F(x) = I(0 \le x \le \theta) \frac{P(Z \le x) - P(Z \le 0)}{P(Z \le \theta) - P(Z \le 0)} + I(x > \theta)$$

**Compute** the value of $F(30)$ for $\mu = 40, \sigma^2 = 100, \theta = 50$ (we'll use this value later) using `pnorm` to get $P(Z \le z), z = 0, \theta$.

Hint: (a) First explain what role the indicator functions play in the CDF. (b) Think about $X$ as a **conditional random variable**: $X = Z \mid (0 \le Z \le \theta)$.

```{r}
## Prove:
# The first indicator function: 1 if x is between 0 and theta, 0 otherwise
# The second indicator function: 1 if x > theta, 0 if x <= theta
# In the case 0 <= x <= theta, the CDF is:
```
$F(x) = \frac{P(Z \le x) - P(Z \le 0)}{P(Z \le \theta) - P(Z \le 0)}$
```{r}
# In the case where x > theta:
```
$F(x) = 1$
```{r}
# In the case where x < theta:
```
$F(x) = 0$
```{r}
# Consequently, we can conclude the following expression for the CDF which handles all three cases:
```
$F(x) = I(0 \le x \le \theta) * \frac{P(Z \le x) - P(Z \le 0)}{P(Z \le \theta) - P(Z \le 0)} + I(x > \theta)$
```{r}
## Compute
mu <- 40
sigma <- sqrt(100)
theta <- 50

P_Z_leq_0 <- pnorm(0, mean = mu, sd = sigma)
P_Z_leq_30 <- pnorm(30, mean = mu, sd = sigma)
P_Z_leq_theta <- pnorm(theta, mean = mu, sd = sigma)

F_30 <- (P_Z_leq_30 - P_Z_leq_0) / (P_Z_leq_theta - P_Z_leq_0)
F_30
```
### Part (b) (2 pts)

Use Monte Carlo integration to estimate

$$P(X \le 30) = E(I(X \le 30))$$

for $\mu = 40$, $\sigma^2 = 100$, and $\theta = 50$. You can use `rnorm` to generate random variables $Y \sim N(\mu, \sigma^2$) and then just keep those that fall into the region $[0, 50]$. You should generate enough $Y$ so that you have at least 5000 $X$ after discarding $Y$ outside the $[0, 50]$ interval. Create a 95% confidence interval for $F(30)$. Does your interval include the value you computed in (a)?

```{r}
z_samples <- rnorm(100000, mean = mu, sd = sigma)
x_samples <- z_samples[z_samples >= 0 & z_samples <= theta]

p_leq_30 <- mean(x_samples <= 30)
p_leq_30
sd_e <- sd(p_leq_30) / sqrt(length(x_samples))
ci <- p_leq_30 + c(-1,1)*qnorm(0.975)*sd_e

p_leq_30
ci
```

### Part (c) (2 pts)

The empirical cumulative distribution function is given by $$\hat F(x) = \frac{1}{n} \sum_{i=1}^n I(X_i \le x)$$

Generate the sampling distribution of $\hat F(30)$ from sample of 56 units from the distribution in part (b): $(\mu = 40, \sigma^2 = 100, \theta = 50)$. Use 1000 replications of samples of size 56.

Using the value of $F(30)$ from part (a), estimate the bias and mean squared error of the sample mean of 56 observations when estimating. Include a 99% confidence interval for each.

```{r}
mu <- 40
sigma <- sqrt(100)
theta <- 50
n <- 56
n_reps <- 1000
x_value <- 30

F_30 <- (pnorm(30, mean = mu, sd = sigma) - pnorm(0, mean = mu, sd = sigma)) / (pnorm(theta, mean = mu, sd = sigma) - pnorm(0, mean = mu, sd = sigma))

generate_truncated_sample <- function(n, mu, sigma, theta) {
  z_samples <- rnorm(n, mean = mu, sd = sigma)
  x_samples <- z_samples[z_samples >= 0 & z_samples <= theta]
  
  while (length(x_samples) < n) {
    z_samples <- rnorm(n, mean = mu, sd = sigma)
    x_samples <- c(x_samples, z_samples[z_samples >= 0 & z_samples <= theta])
    x_samples <- x_samples[1:n]
  }
  return(x_samples)
}

F_hat_30 <- replicate(n_reps, {
  x_sample <- generate_truncated_sample(n, mu, sigma, theta)
  mean(x_sample <= x_value)
})

bias <- mean(F_hat_30) - F_30

mse <- mean((F_hat_30 - F_30)^2)

alpha <- 0.01
ci_99 <- quantile(F_hat_30, probs = c(alpha/2, 1 - alpha/2))

list(
  bias = bias,
  mse = mse,
  mean_F_hat_30 = mean(F_hat_30),
  ci_99 = ci_99
)
```

### Part (d) (2 pts)

For truncated Normal distributions where the truncation is not too asymmetric, another option is to use $\bar X$ to estimate $\mu$ and $S^2$ (the sample variance) to estimate $\sigma^2$.

Repeat part (c) by estimating $P(X \le 30)$ using the CDF given in part (a), using $\mu = \bar X$ and $\sigma^2 = S^2$ and $\theta = 50$ as parameters. Compute the bias and mean squared error for this estimator.
```{r}

```
### Part (e) (2 pts)

Using either the estimator from (c) or (d), estimate $P(X \le 30)$ (assuming $\theta = 50$) for the fish data. Why did you pick this estimator? Compare the two estimators in (c) and (d) on bias and MSE.
```{r}

```
