---
title: "HW 07"
author: "Eleanor King, elejking"
date: "Due 2024-11-01 at 9:00pm"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
set.seed(303203)
```

## Question 1 (2 points)

In a previous week we used the Laplace distribution as a candidate distribution for the standard Normal $N(0,1)$ distribution using an accept-reject algorithm.

Recall that the probability distribution for a standard Normal is given by:

$$f(x) = \frac{1}{\sqrt{2 \pi}} \exp\left\{ - \frac{x^2}{2} \right\}$$

and the Laplace is given by
$$g(x) = \frac{1}{2} \exp\left\{- |x| \right\}$$

And here is a source of Laplace distributed random variables.

```{r}
rlaplace <- function(n, mean = 0) {
  s <- 2 * rbinom(n, size = 1, p = 0.5) - 1
  m <- rexp(n) 
  s * m + mean
}
```

Implement an importance sampling algorithm for standard Normals using the Laplace distribution as the envelope distribution in order to estimate

$$E(X^2)$$
where $X \sim N(0, 1)$. Use 1000 samples and provide a 95\% confidence interval for $E(X^2)$.

```{r}
n <- 1000
samples <- rlaplace(n)

f_x <- function(x) {
  (1 / sqrt(2 * pi)) * exp(-x^2 / 2)
}

g_x <- function(x) {
  0.5 * exp(-abs(x))
}

weights <- f_x(samples) / g_x(samples)
X_2 <- samples^2 * weights

E_X2 <- mean(X_2)
std_error <- sd(X_2) / sqrt(n)

conf_interval <- c(E_X2 - 1.96 * std_error, E_X2 + 1.96 * std_error)

E_X2
conf_interval
```
## Question 2 (5 pts)

Consider the density (known up to a constant) given by:

$$f(x) \propto \sin(\pi  x^2), \quad 0 < x < 1$$

```{r}
curve(sin(pi * x^2), ylab = "f*(x)")
```

### Part (a) (2 pts)

We want to estimate $E(X)$ using importance sampling (resampling).

Using a uniform [0, 1] distribution as the envelope, use (reweighted) importance sampling to estimate $E(X)$. Estimate the variance of the **estimator** (we'll compare it to another estimator in part (b)).

```{r}
f_x <- function(x) {
  sin(pi * x^2)
}

n <- 1000
samples <- runif(n)
weights <- f_x(samples)
E_X <- sum(samples * weights) / sum(weights)
weighted_X <- samples * weights
variance_estimator <- sum((weighted_X - E_X)^2) / (n - 1)

E_X
variance_estimator
```

### Part (b) (3 pt)

The uniform distribution is a special case of the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) with parameters $\alpha = \beta = 1$. It works as an envelope, but it does not very carefully follow the target function: 
$$E(X) \propto \int_0^1 x \sin(\pi x^2) \, dx$$
```{r}
curve(x * sin(pi * x^2))
```

Propose a set of parameters $\alpha$ and $\beta$ that leads to a better envelope distribution. Use this distribution (see the `rbeta` function) to implement importance sampling to estimate $E(X)$ and the variance of the estimator. Did this estimator have lower variance than the estimator based on the uniform candidate?

Useful tip: A Beta($\alpha, \beta$) with $\alpha > 1$ and $\beta > 1$ will have a mode at $(\alpha - 1) / (\alpha + \beta - 2)$. This can be useful to graph candidate distributions against the target:

```{r}
## target function has a mode at approximately 0.76
target_height <- 0.76 * sin(pi * 0.76^2)

## candidate beta distribution alpha = beta = 2, so a mode at 1/2
cand_height <- dbeta(1/2, 2, 2)

tc_ratio <- target_height/cand_height

curve(x * sin(pi * x^2))
curve(tc_ratio * dbeta(x, 2, 2), add = TRUE, col = "red")
curve(tc_ratio * dbeta(x, 3.5, 1.5), add = TRUE, col = "red")

## Setting alpha = 3.5, beta = 1.5 based 
##on the formula for calculating mode and 
##the target function's approximate mode.

target <- function(x) x * sin(pi * x^2)
alpha <- 3.5
beta <- 1.5

set.seed(406)
n <- 10000
samples <- rbeta(n, alpha, beta)
weights <- target(samples) / dbeta(samples, alpha, beta)
EX_estimator <- mean(samples * weights)
var_estimator <- var(samples * weights) / n

EX_estimator
var_estimator

## Uniform variance estimator:
samples_unif <- runif(n)
weights_unif <- target(samples_unif) / dunif(samples_unif)
EX_estimator_unif <- mean(samples_unif * weights_unif)
var_estimator_unif <- var(samples_unif * weights_unif) / n

EX_estimator_unif
var_estimator_unif
## var_estimator_unif is larger than 
##var_estimator, so the estimator does 
##have lower variance than the estimator 
##based on the uniform candidate.
```



## Question 3 (4 pts)

Consider sampling $n$ pairs $(Y_i, X_i)$ from a very large population of size $N$. We will assume that the population is so large that we can treat $n/N \approx 0$, so that all pairs in our sample are effectively independent.

For the population, you want to relate $Y$ and $X$ as a linear function:
$$Y_i = \beta_0 + \beta_1 X_i + R_i$$
where 
\[
\begin{aligned}
\beta_1 &= \frac{\text{Cov}(X,Y)}{\text{Var}(X)} \\
\beta_0 &= E(Y) - \beta_1 E(X) \\
R_i &= Y_i - \beta_0 - \beta_1 X_i
\end{aligned}
\]

The line described by $\beta_0$ and $\beta_1$ is the "population regression line". We don't get to observe $R_i$ for our sample, but we can estimate $\beta_0$ and $\beta_1$ to get estimates of $R_i$.

### Part (a) (2 points)

The `lm` function in R can estimate $\beta_0$ and $\beta_1$ using sample means and variances. Since these estimators are based on sample means, we can use the **central limit theorem** to justify confidence intervals for $\beta_0$ and $\beta_1$ (we won't do so rigorously in this setting).

Use the `lm` function to estimate $\beta_0$ and $\beta_1$. Apply the `confint` function to the results to get 95% confidence intervals for the $\beta_1$ parameter.

The estimated residuals ($\hat R_i$) can be found by applying the `resid` function to the result of `lm`. Provide a density plot of these values (see `geom_density`). Do they give you any reason to be concerned about the validity of the Central Limit Theorem approximation?

```{r}
set.seed(406)
N <- 100000
X <- rnorm(N, mean = 5, sd = 2)
beta_0 <- 1
beta_1 <- 2
R <- rnorm(N, mean = 0, sd = 1)
Y <- beta_0 + beta_1 * X + R

n <- 10000
sample_pairs <- sample(1:N, n)
X_sample <- X[sample_pairs]
Y_sample <- Y[sample_pairs]

model <- lm(Y_sample ~ X_sample)
summary(model)
conf_int <- confint(model) # by default, 95% confint
print(conf_int)

residuals <- resid(model)
ggplot(data.frame(residuals), aes(x = residuals)) +
  geom_density(fill = "blue") +
  labs(title = "Density Plot of Residuals", x = "Residuals", y = "Density")
```
Given that the density of the residuals somewhat follow a normal distribution (no obvious skew, heavy tails, etc.), we do not need to be concerned about the validity of the Central Limit Theorem approximation for confidence intervals. 

### Part (b) (2 pts)

You can use the `coef` function to get just the estimators $\hat \beta_0$ and $\hat \beta_1$. Use the `boot` package to get basic and percentile confidence intervals for just $\beta_1$. You will need to write a custom function to give as the `statistic` argument to `boot`. Use at least 1000 bootstrap samples. You can use `boot.ci` for the confidence intervals.

Comment on the assumptions required for the bootstrap intervals.

```{r}
library(boot)
data = data.frame(Y = Y_sample, X = X_sample)
B <- 1000

estimate_beta1 <- function(data, indices) {
  sample_data <- data[indices, ]
  model = lm(Y ~ X, data = sample_data)
  return(coef(model) [2])
}

bootstrap <- boot(data = data, statistic = estimate_beta1, R = B)

ci <- boot.ci(bootstrap, type = "basic")
ci_perc <- boot.ci(bootstrap, type = "perc")

print(ci)
print(ci_perc)

```

## Question 4 (7 pts)

Suppose that instead of sampling pairs, we first identified some important values of $x$ that we wanted to investigate. Treating these values as fixed, we sampled a varying number of $Y_i$ for each $x$ value. For these data, we'll attempt to model the conditional distribution of $Y \, | \, x$ as:
$$Y \, | \, x = \beta_0 + \beta_1 x + \epsilon$$
where $\epsilon$ epsilon is assumed to be symmetric about zero (therefore, $E(\epsilon) = 0$) and the variance of $\epsilon$ does not depend on $x$ (a property called "homoskedasticity"). These assumptions are very similar to the population regression line model (as $E(R_i) = 0$ by construction), but cover the case where we want to design the study on particular values (a common case is a randomized trial where $x$ values are assigned from a known procedure and $Y$ is measured after).

### Part (a) (3 pts)

Let's start with some stronger assumptions and then relax them in the subsequent parts of the question.

The assumptions that support the Central Limit Theorem in Question 1 can also be used to assume that $\epsilon \sim N(0, \sigma^2)$ so that:

$$Y \mid x \sim N(\beta_0 + \beta_1 x, \sigma^2)$$

We've noticed that the Normal distribution has "light tails" and assumptions based on Normality can be sensitive to outliers.

Instead, suppose we we model $\epsilon$ with a scaled $t$-distribution with 4 degrees of freedom (i.e., has fatter tails than the Normal distribution): 
$$\epsilon \sim \frac{\sigma}{\sqrt{2}} t(4) \Rightarrow \text{Var}(\epsilon) = \sigma^2$$
(The $\sqrt{2}$ is there just to scale the $t$-distribution to have a variance of 1. More generally, if we picked a differed degrees of freedom parameter $v$, this would be replaced with $\sqrt{v/(v-2)}$.)


One way to get an estimate of the distribution of $\hat \beta_1$ is the following algorithm:


1. Estimate $\beta_0$, $\beta_1$, and $\sigma$ using linear regression (you can get the $\hat \sigma$ using `summary(model)$sigma`),
2. For all the $x_i$ in the sample, generate $\hat y_i = \hat \beta_0 + \hat \beta_1 x_i$ (you can use `predict(model)` to get $\hat y$)
3. For $B$ replications, generate $Y_i^* = \hat y_i + \epsilon_i*$, where 
$$\epsilon^* \sim \frac{\hat \sigma}{\sqrt{2}} t(4)$$
4.  For each replication, use linear regression to estimate $\hat \beta_1^*$. 
5.  Use the $\alpha/2$ and $1 - \alpha/2$ quantiles of the bootstrap distribution to get the confidence intervals:
$$[2 \hat \beta_1 - \hat \beta_1^*(1 - \alpha/2), 2 \hat \beta_1 - \hat \beta_1^*(\alpha/2)]$$
To avoid double subscripts I've written $\hat \beta^*_1(1 - \alpha/2)$ as the upper $1 - \alpha/2$ quantile of the bootstrap (and likewise for the lower $\alpha/2$ quantile).

You may note that this is a "basic" basic bootstrap interval. In fact, this procedure (fitting parameters, then simulating from a model) is known as a **parametric bootstrap**.

Use the algorithm above to generate a confidence interval for $\beta_1$. Compare it to the fully parametric interval produced in Question 1(a). Which is larger or smaller?

Note: The `boot` function does have the option of performing a parametric bootstrap using a user supplied `rand.gen` function. Feel free to use this functionality, but you may find it easier to implement the algorithm directly.

```{r}
library(MASS)

B <- 1000
alpha <- 0.05

set.seed(123)
n <- 50
x <- runif(n, min = 1, max = 10)
beta_0 <- 3
beta_1 <- 2
sigma <- 1.5

y <- beta_0 + beta_1 * x + (sigma / sqrt(2)) * rt(n, df = 4)
model <- lm(y ~ x)
summary_model <- summary(model)

beta_0_hat <- coef(model)[1]
beta_1_hat <- coef(model)[2]
sigma_hat <- summary_model$sigma

y_hat <- predict(model)

beta_1_bootstrap <- numeric(B)

for (i in 1:B) {
  epsilon_star <- (sigma_hat / sqrt(2)) * rt(n, df = 4)
  y_star <- y_hat + epsilon_star
  model_star <- lm(y_star ~ x)
  beta_1_bootstrap[i] <- coef(model_star)[2]
}

lower_bound <- 2 * beta_1_hat - quantile(beta_1_bootstrap, 1 - alpha / 2)
upper_bound <- 2 * beta_1_hat - quantile(beta_1_bootstrap, alpha / 2)
bootstrap_ci <- c(lower_bound, upper_bound)
print(bootstrap_ci)

parametric_ci <- confint(model, level = 1 - alpha)[2, ]
print(parametric_ci)
```


### Part (b) (3 pts)

As an alternative to sampling from an assumed distribution for $\epsilon$, we can replace step (3) in the previous algorithm with 

3. Draw a sample (with replacement) from $\hat \epsilon_i$ and make $Y_i^* = \hat y_i + \epsilon_i^*$

Implement this version of a parametric bootstrap. Feel free to use the `boot` package. 

```{r}
B <- 1000
alpha <- 0.05

model <- lm(y ~ x)
beta_1_hat <- coef(model)[2]
y_hat <- predict(model)
residuals <- resid(model)

bootstrap_beta_1 <- function(data, indices) {
  epsilon_star <- residuals[indices]
  y_star <- y_hat + epsilon_star
  model_star <- lm(y_star ~ x)
  coef(model_star)[2]
}

boot_results <- boot(data = residuals, statistic = bootstrap_beta_1, R = B)

basic_ci <- boot.ci(boot_results, type = "basic", index = 1)
perc_ci <- boot.ci(boot_results, type = "perc", index = 1)
parametric_ci <- confint(model, level = 1 - alpha)[2, ]

print(basic_ci$basic[4:5])
print(perc_ci$percent[4:5])
print(parametric_ci)

```

### Part (c) (1 pt)

Discuss the differences in the four types of intervals we created (fully parametric in 1(a), non-parametric bootstrap in 1(b), two variations of parametric bootstrap in 2(a) and 2(b)). When analyzing a particular data set, when would you pick one method over the another methods?

In the fully parametric confidence interval that we created in 1(a), we assumed a normal distribution for the residuals and simulated datasets based on that parametric model. This differs from the non-parametric bootstrap in 1(b) in which we didn't assume a distribution for the residuals and instead randomly sampled from the data, then estimated the model. In the parametric bootstrap variation from 2(a), we assumed a parametric, but non-normal form for the distribution of the residuals. Lastly, in the parametric bootstrap variation from 2(b), we didn't make an assumption about the distribution of the errors, but assumed that the functional form of the model was correct. 

Consequently, it is best to use a fully parametric bootstrap when we know the model form and error distribution. It is best to use the non-parametric distribution when we don't know the residual distribution. It is best to use the parametric bootstrap variation from 2(a) when we know that the residual distribution is heavy tailed. It is best to use the parametric bootstrap variation from 2(b) when we know the form of the model, but the residuals appear to not be non-normal.

## Question 5 (2 pts)

Read the paper "THE RISK OF CANCER ASSOCIATED WITH SPECIFIC MUTATIONS OF BRCA1 AND BRCA2 AMONG ASHKENAZI JEWS." Briefly summarize the paper. Make sure to discuss the research question, data source, methods, and results. How did the authors use the bootstrap procedure in this paper?


In "THE RISK OF CANCER ASSOCIATED WITH SPECIFIC MUTATIONS OF BRCA1 AND BRCA2 AMONG ASHKENAZI JEWS", the author's sought to analyze the risk of cancer in Jewish men and women for a large sample from the Washington D.C. area. Over 2% of Ashkenazi Jews carry 185delAG and 5382insC mutations in BRCA1 and 6174delT mutations in BRCA2, leading to increased risks of breast, ovarian, and prostate cancer. Using blood samples from 5,318 Jewish subjects, the authors estimated the risk of cancer by comparing medical histories of carriers of the BRCA1 and BRCA2 mutations with non-carriers. From the sample, 120 carriers were identified. There was no significant difference in the risk of breast cancer among BRCA1 mutation carriers and BRCA2 mutation carriers.

In order to account for cancer risk increasing with age, the authors used the bootstrap procedure to calculate confidence intervals to estimate the variance of the cancer risk estimates. Using bootstrapping, they repeatedly sampled with replacement. They used this to quantify uncertainty in the observed data.
